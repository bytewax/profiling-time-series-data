# Profiling Streaming Time Series Data

- Skill level
    
    **Intermediate, some knowledge of windowing and pandas will help**
    
- Time to complete
    
    **Approx. 25 min**
    

Introduction: *In this guide, we will show you how you can combine [bytewax](https://github.com/bytewax/bytewax) with [ydata-profiling](https://github.com/ydataai/ydata-profiling) to profile and understand the quality of your streaming data!*

## ****Prerequisites****

**Python modules** bytewax==0.16.2 ydata-profiling==4.3.1

## Your Takeaway

*You'll be able to handle and structure data streams into snapshots using Bytewax, and then analyze them with ydata-profiling to create a comprehensive report of data characteristics for each device at each time interval.*

## Table of content

- [Resources](https://github.com/bytewax/profiling-time-series-data/tree/main#resources)
- [Data Profiling](https://github.com/bytewax/profiling-time-series-data/tree/main#data-profiling)
- [Step 1. Environmental Sensor Telemetry Dataset](https://github.com/bytewax/profiling-time-series-data/tree/main#step-1-environmental-sensor-telemetry-dataset)
- [Step 2. Inputs and parsing](https://github.com/bytewax/profiling-time-series-data/tree/main#step-2-inputs-and-parsing)
- [Step 3. Windowing](https://github.com/bytewax/profiling-time-series-data/tree/main#step-3-windowing)
- [Step 4. Profile report](https://github.com/bytewax/profiling-time-series-data/tree/main#step-4-profile-report)
- [Summary](https://github.com/bytewax/profiling-time-series-data/tree/main#summary)

## Resources

[Github link](https://github.com/bytewax/profiling-time-series-data)

[Jupyter Notebook link](https://colab.research.google.com/gist/awmatheson/d30d520f693d1ddc4319ab3bc87eccf2/ydata-profiling-streaming.ipynb)

[Data sample link](https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k)

## Data Profiling

Instead of the usual approach, where data quality is assessed during the creation of the data warehouse or dashboard solution, it is a cheaper, more effective and ultimately more robust approach to monitor the quality closer to the source, which is a great fit for stream processing, since most data is created in real-time. This will prevent any data quality issues from multiplying in downstream tables and ending up in customer-facing services.

In what concerns data profiling, [ydata-profiling](https://github.com/ydataai/ydata-profiling) has consistently been a [crowd favorite](https://medium.com/ydata-ai/auditing-data-quality-with-pandas-profiling-b1bf1919f856), either for [tabular](https://ydata-profiling.ydata.ai/docs/master/pages/getting_started/examples.html) or [time-series](https://medium.com/towards-data-science/how-to-do-an-eda-for-time-series-cbb92b3b1913) data. And no wonder why — it’s one line of code for an extensive set of analysis and insights.

Let's see it in action!

## Step 1. Environmental Sensor Telemetry Dataset 

Let's download a subset of the [Environmental Sensor Telemetry Dataset](https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k) (License — CC0: Public Domain), which contains several measurements of temperature, humidity, carbon monoxide liquid petroleum gas, smoke, light, and motion from different IoT devices

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/utils/get-dataset.sh#L1

In a production environment, these measurements would be continuously generated by each device, and the input would look like what we expect in a streaming platform such as [Kafka](https://bytewax.io/guides/enriching-streaming-data). 

## Step 2. Inputs and parsing

To simulate a stream of data, we will use the Bytewax CSVInput connector to read the CSV file we downloaded one line at a time. In a production use case, you could easily swap this out with the [KafkaInput](https://www.bytewax.io/apidocs/bytewax.connectors/kafka) connector.

First, let’s make some necessary imports:

https://github.com/bytewax/profiling-time-series-data/blob/9f12b285247de91befc5f3d46a083a7bcf2b9b23/dataflow.py#L1C1-L6C1

Then, we define our dataflow object and add our CSV input.

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/dataflow.py#L14-L15

Afterward, we will use a stateless `map` method where we pass in a function to convert the string to a `datetime` object and restructure the data to the format (device_id, data).

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/dataflow.py#L17-L26

The `map` method will make the change to each data point in a stateless way. The reason we have modified the shape of our data is so that we can easily group the data in the next steps to profile data for each device separately rather than for all of the devices simultaneously.


## Step 3. Windowing
Now we will take advantage of the stateful capabilities of bytewax to gather data for each device over a duration of time that we have defined. ydata-profiling expects a snapshot of the data over time, therefore the `window` operator is the perfect method to use to do this.

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/dataflow.py#L28-L52

In ydata-profiling, we are able to produce summary statistics for a Pandas DataFrame which is specified for a particular context. For instance, in our example, we can produce snapshots of data referring to each IoT device or to particular time frames.


## Step 4. Profile Report

After the snapshots are defined, leveraging ydata-profiling is as simple as calling the `PorfileReport` method for each of the dataframes we would like to analyze:

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/dataflow.py#L56-L73

## Step 5. Kicking Things off
Once the profile is complete, the dataflow expects some output, so we can use the built-in `StdOutput` to print the device that was profiled and the time it was profiled at that was returned by the profile function in the map step:

https://github.com/bytewax/profiling-time-series-data/blob/9b5985e778157b55b2bef412a5cda0cd790d0dc2/dataflow.py#L75

And we are ready to run our program! You can clone this repository to your machine and run the following commands:

https://github.com/bytewax/profiling-time-series-data/blob/1eb17525b41d11b46478fef5ec95693e22bac62e/run.sh#L3

## Summary

We can now use the profiling reports to validate the data quality, check for changes in schemas or data formats, and compare the data characteristics between different devices or time windows.

Being able to process and profile incoming data appropriately opens up a plethora of use cases across different domains, from the correction of errors in data schemas and formats to the highlighting and mitigation of additional issues that derive from real-world activities, such as *anomaly detection* (e.g., fraud or intrusion/threats detection), *equipment malfunction*, and other events that deviate from the expectations (e.g., *data drifts* or misalignment with business rules).

_This guide was written with the support of the [Ydata team](https://ydata.ai/)_

## We want to hear from you!

If you have any trouble with the process or have ideas about how to improve this document, come talk to us in the #troubleshooting Slack channel!

## Where to next?

- [Switch this tutorial to use Kafka inputs](https://bytewax.io/guides/enriching-streaming-data)

See our full gallery of tutorials →

[Share your tutorial progress!](https://twitter.com/intent/tweet?text=I%27m%20mastering%20data%20streaming%20with%20%40bytewax!%20&url=https://bytewax.io/tutorials/&hashtags=Bytewax,Tutorials)
